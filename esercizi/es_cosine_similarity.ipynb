{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c0e2f6-5d79-4b93-b437-2d7b4de711c9",
   "metadata": {},
   "source": [
    "## Utilizzando il dataset visto nella lezione del topic modeling, individuare il documento del dataset, pi√π simile ad uno dei documenti a scelta dello stesso dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113a4579-dfea-4e77-90a6-3b22c9fae206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3bcbfe-aed5-453b-83b5-f165172e2963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1        Reconstructing Subject-Specific Effect Maps   \n",
       "1   2                 Rotation Invariance Neural Network   \n",
       "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3   4  A finite element approximation for the stochas...   \n",
       "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
       "\n",
       "                                            ABSTRACT  Computer Science  \\\n",
       "0    Predictive models allow subject-specific inf...                 1   \n",
       "1    Rotation invariance and translation invarian...                 1   \n",
       "2    We introduce and develop the notion of spher...                 0   \n",
       "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "\n",
       "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0        0            0           0                     0   \n",
       "1        0            0           0                     0   \n",
       "2        0            1           0                     0   \n",
       "3        0            1           0                     0   \n",
       "4        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../datasets/Lezione_7-Topic_modeling/dataset_Research_Article.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0449bbed-2682-46b7-bdcb-25cc328855dd",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22121e63-2015-46e4-9452-dc9a30b9a2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Reconstructing Subject-Specific Effect Maps  P...\n",
       "1    Rotation Invariance Neural Network  Rotation i...\n",
       "2    Spherical polyharmonics and Poisson kernels fo...\n",
       "3    A finite element approximation for the stochas...\n",
       "4    Comparative study of Discrete Wavelet Transfor...\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset[\"TITLE\"] + dataset[\"ABSTRACT\"]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "545fdaaa-4ebb-4c89-a715-d8c78d036bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aless\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#utils\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stopwords_en = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5d36c5-4598-4c53-828e-a7b3da8181d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s:str):\n",
    "    #lowercase\n",
    "    s = s.lower()\n",
    "    \n",
    "    #punctuation\n",
    "    for c in string.punctuation:\n",
    "        s = s.replace(c,\" \")\n",
    "\n",
    "    #lemmatization\n",
    "    doc = nlp(s)\n",
    "    s = \" \".join(token.lemma_ for token in doc)\n",
    "\n",
    "    #stopwords\n",
    "    s = \" \".join(word for word in s.split() if word not in stopwords_en)\n",
    "    \n",
    "    #remove numbers\n",
    "    s = re.sub(r\"\\d\",\"\",s)\n",
    "\n",
    "    #remove multiple spaces\n",
    "    s = re.sub(r\" +\",\" \",s)\n",
    "    return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9ab3e50-d901-497b-b9be-b1c1fda79a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean = X.apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca756c5-7711-4d35-929d-e8914818346e",
   "metadata": {},
   "source": [
    "## Word Embedding\n",
    "For each document in corpus, we compute the mean embedding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16a4854d-e248-41e2-b1fd-0bd9f53196fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "831ab030-63ca-46ad-92ed-51ad734ff7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "print(list(gensim.downloader.info()['models']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d155a63-d3ae-49f9-9fa6-c46e1af19acf",
   "metadata": {},
   "source": [
    "In this exercise the `glove-wiki-gigaword-200` model is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a315566-d7d6-42b0-9355-a5c1862409bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = gensim.downloader.load(\"glove-wiki-gigaword-200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cc508bb-a148-4c63-852d-06f5f89ac64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding(s:str):\n",
    "    \"\"\"\n",
    "    Compute mean embedding vector for a sentence.\n",
    "    \"\"\"\n",
    "    v = np.zeros(200) #same dimension of final embedding\n",
    "    counter = 0\n",
    "    for word in s.split():\n",
    "        if word in glove_model.key_to_index.keys():\n",
    "            v += glove_model.get_vector(word)\n",
    "            counter += 1\n",
    "    return v/counter if counter > 0 else v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c385dbe5-bf7c-43d6-a2f8-0b615bb62594",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = X_clean.apply(compute_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e81393f0-5a28-4301-aad5-44b0e813f454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.22885676364413188, 0.1617810904739637, 0.12...\n",
       "1    [0.16675768384955963, 0.313653826146861, 0.115...\n",
       "2    [0.18669769784160467, 0.16619212610477752, -0....\n",
       "3    [0.26152576006164674, 0.25411178452295163, 0.2...\n",
       "4    [0.21645674137573223, 0.19605113154975698, 0.0...\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f13e23a-020c-4814-a562-8a775f2031cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a013852-7b68-4493-8376-2ab08d22e347",
   "metadata": {},
   "source": [
    "`embeddings` is a pandas Series where each element is a 200 elements vector, that is the mean embedding of a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb65b6-7282-4a0d-ad61-721df2d18181",
   "metadata": {},
   "source": [
    "## Cosine distances\n",
    "Find the most similar document of the 176-th document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f9b6309-7847-481d-8982-cba98516e796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20972, 200)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_array = np.array([row for row in embeddings])\n",
    "embeddings_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cd5df35-c835-4651-9616-948b39974fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def find_closest_doc(idx:int):\n",
    "    \"\"\"\n",
    "    Find the most similar document of the idx-th element in the dataset.\n",
    "    The cosine distance is used as similarity metrics.\n",
    "    \"\"\"\n",
    "    distances = cdist(np.expand_dims(embeddings_array[idx],axis=0), np.delete(embeddings_array,idx,0), 'cosine')\n",
    "    closest_index = np.argmin(distances)\n",
    "    return closest_index if closest_index < idx else closest_index + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7906138f-5c5f-4461-96f2-6ed56a4b901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc n. 42:\n",
      "Probing valley filtering effect by Andreev reflection in zigzag graphene nanoribbon  Ballistic point contact (BPC) with zigzag edges in graphene is a main\n",
      "candidate of a valley filter, in which the polarization of the valley degree of\n",
      "freedom can be selected by using a local gate voltage. Here, we propose to\n",
      "detect the valley filtering effect by Andreev reflection. Because electrons in\n",
      "the lowest conduction band and the highest valence band of the BPC possess\n",
      "opposite chirality, the inter-band Andreev reflection is strongly suppressed,\n",
      "after multiple scattering and interference. We draw this conclusion by both the\n",
      "scattering matrix analysis and the numerical simulation. The Andreev reflection\n",
      "as a function of the incident energy of electrons and the local gate voltage at\n",
      "the BPC is obtained, by which the parameter region for a perfect valley filter\n",
      "and the direction of valley polarization can be determined. The Andreev\n",
      "reflection exhibits an oscillatory decay with the length of the BPC, indicating\n",
      "a negative correlation to valley polarization.\n",
      "\n",
      "----------\n",
      "Closest doc is the n. 17249:\n",
      "Giant paramagnetism induced valley polarization of electrons in charge-tunable monolayer MoSe2  For applications exploiting the valley pseudospin degree of freedom in\n",
      "transition metal dichalcogenide monolayers, efficient preparation of electrons\n",
      "or holes in a single valley is essential. Here, we show that a magnetic field\n",
      "of 7 Tesla leads to a near-complete valley polarization of electrons in MoSe2\n",
      "monolayer with a density 1.6x10^{12} cm^{-2}; in the absence of exchange\n",
      "interactions favoring single-valley occupancy, a similar degree of valley\n",
      "polarization would have required a pseudospin g-factor exceeding 40. To\n",
      "investigate the magnetic response, we use polarization resolved\n",
      "photoluminescence as well as resonant reflection measurements. In the latter,\n",
      "we observe gate voltage dependent transfer of oscillator strength from the\n",
      "exciton to the attractive-Fermi-polaron: stark differences in the spectrum of\n",
      "the two light helicities provide a confirmation of valley polarization. Our\n",
      "findings suggest an interaction induced giant paramagnetic response of MoSe2,\n",
      "which paves the way for valleytronics applications.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx_doc = 42\n",
    "closest_idx = find_closest_doc(idx_doc)\n",
    "\n",
    "print(f\"Doc n. {idx_doc}:\\n{X[idx_doc]}\")\n",
    "print(\"-\"*10)\n",
    "print(f\"Closest doc is the n. {closest_idx}:\\n{X[closest_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a932e75-d795-41cd-bbcc-fb5d2b2ead44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ce7f5-63a7-42af-ab39-366c65aa2793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
